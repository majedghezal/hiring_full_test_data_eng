ğŸ“Š Hiring Full Test â€“ Data Engineer
Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre dâ€™un test technique pour un poste de Data Engineer chez FULL.
Il consiste Ã  implÃ©menter un pipeline ETL pour charger des donnÃ©es de transactions dans une base SQLite, avec vÃ©rifications et corrections automatiques.

ğŸ—‚ Contenu du projet
Fichier	Description
fullETL.py	Script principal du pipeline ETL : Extract â†’ Transform â†’ Load
test.py	Fichier de tests unitaires pour valider le fonctionnement du pipeline
retail_15_01_2022.csv	DonnÃ©es de transactions Ã  importer (input)
retail.db	Base SQLite contenant les transactions
fullqueries.sql	RequÃªtes SQL rÃ©pondant aux questions analytiques demandÃ©es
deployment.pdf	Proposition dâ€™architecture pour le dÃ©ploiement automatique sur AWS via Terraform
ğŸš€ ExÃ©cution du pipeline
bash
Copier
Modifier
python fullETL.py
ğŸ“Œ Assurez-vous d'avoir pandas installÃ© (pip install pandas)

âœ… Lancer les tests
bash
Copier
Modifier
python -m unittest test.py
ğŸ’¡ Ã€ propos de Docker / Makefile
Je nâ€™ai pas ajoutÃ© de fichier Docker ou Makefile car l'exÃ©cution est simple et directe avec les commandes ci-dessus.
Une solution complÃ¨te de dÃ©ploiement est proposÃ©e dans deployment.pdf.

âš™ï¸ DÃ©tails du pipeline ETL
ğŸ”¹ Extract
Lecture du fichier CSV contenant les transactions

ğŸ”¹ Transform
VÃ©rification des colonnes et des valeurs obligatoires

Nettoyage : suppression des doublons et gestion des quantitÃ©s nÃ©gatives

Correction automatique de la TVA Ã  20% si incorrecte

Extraction de la date depuis le nom du fichier

ğŸ”¹ Load
Insertion dans la base SQLite tout en Ã©vitant les doublons

